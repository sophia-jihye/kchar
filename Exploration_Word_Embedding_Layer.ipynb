{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ :  1.13.1\n",
      "keras.__version__ :  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('tf.__version__ : ', tf.__version__)\n",
    "print('keras.__version__ : ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vocab_unpack(vocab):\n",
    "    return vocab['idx2word'], vocab['word2idx'], vocab['idx2char'], vocab['char2idx']\n",
    "\n",
    "vocab_mapping = np.load('data/ptb/vocab.npz')\n",
    "idx2word, word2idx, idx2char, char2idx = vocab_unpack(vocab_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'federal'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[100]\n",
    "# word2idx.tolist()['hope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained Model (with 1 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmlab/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dmlab/anaconda3/envs/keras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "chars (InputLayer)              (20, 35, 21)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chars_embedding (Embedding)     (20, 35, 21, 15)     765         chars[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (20, 35, 21, 50)     800         chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (20, 35, 20, 100)    3100        chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (20, 35, 19, 150)    6900        chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (20, 35, 18, 200)    12200       chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (20, 35, 17, 200)    15200       chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (20, 35, 16, 200)    18200       chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (20, 35, 15, 200)    21200       chars_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (20, 35, 1, 50)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (20, 35, 1, 100)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (20, 35, 1, 150)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (20, 35, 1, 200)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (20, 35, 1, 200)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (20, 35, 1, 200)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (20, 35, 1, 200)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (20, 35, 1, 1100)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (20, 35, 1100)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (20, 35, 1100)       2422200     reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (20, 35, 1100)       2422200     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (20, 35, 650)        4552600     time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (20, 35, 650)        0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (20, 35, 650)        3382600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (20, 35, 650)        0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (20, 35, 10000)      6510000     dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 19,367,965\n",
      "Trainable params: 19,367,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "from model.LSTMCNN import LSTMCNN\n",
    "\n",
    "opt = pickle.load(open('cv/char-large.pkl', \"rb\"))\n",
    "model = LSTMCNN(opt)\n",
    "model.load_weights('cv/char-large.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442 240 530 163 423  76 620 632 114]\n",
      "[0.05194158 0.04548101 0.04536441 0.04483165 0.04071609 0.04059325\n",
      " 0.04024662 0.04014509 0.03893768]\n"
     ]
    }
   ],
   "source": [
    "def most_similar(emb_layer, pos_word_idxs, neg_word_idxs=[], top_n=10):\n",
    "    weights = emb_layer.weights[0]\n",
    "\n",
    "    mean = []\n",
    "    for idx in pos_word_idxs:\n",
    "        mean.append(weights.value()[idx, :])\n",
    "\n",
    "    for idx in neg_word_idxs:\n",
    "        mean.append(weights.value()[idx, :] * -1)\n",
    "\n",
    "    mean = tf.reduce_mean(mean, 0)\n",
    "\n",
    "    dists = tf.tensordot(weights, mean, 1)\n",
    "    best = tf.math.top_k(dists, top_n)\n",
    "\n",
    "    # Mask words used as pos or neg\n",
    "    mask = []\n",
    "    for v in set(pos_word_idxs + neg_word_idxs):\n",
    "        mask.append(tf.cast(tf.equal(best.indices, v), tf.int8))\n",
    "    mask = tf.less(tf.reduce_sum(mask, 0), 1)\n",
    "\n",
    "    return tf.boolean_mask(best.indices, mask), tf.boolean_mask(best.values, mask)\n",
    "\n",
    "idxs, vals = most_similar(model.layers[-1], [100])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    idxs = sess.run(idxs)\n",
    "    vals = sess.run(vals)\n",
    "    print(idxs)\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand\n",
      "high\n",
      "named\n",
      "program\n",
      "chicago\n",
      "two\n",
      "below\n",
      "warner\n",
      "exchange\n"
     ]
    }
   ],
   "source": [
    "for idx in idxs:\n",
    "    print(idx2word[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
